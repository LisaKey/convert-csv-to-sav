{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "editable": true,
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Une erreur s'est produite : [Errno 2] No such file or directory: '--ip=127.0.0.1'\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "import pyreadstat\n",
    "import sys\n",
    "import chardet\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def export_csv_to_sav(path):\n",
    "    \n",
    "    \n",
    "   \n",
    "\n",
    "    #print(f\"Chargement du fichier CSV depuis : {path}\")\n",
    "    \n",
    "        \n",
    "    try:\n",
    "        # Détecter l'encodage du fichier CSV\n",
    "        with open(path, 'rb') as f:\n",
    "            result = chardet.detect(f.read())\n",
    "\n",
    "        # Lire le fichier CSV avec l'encodage détecté\n",
    "        df_originall = pd.read_csv(path, encoding=result['encoding'])\n",
    "        \n",
    "        # Définir le chemin de sortie pour le fichier SAV\n",
    "        sav_path = path.replace('.csv', '.sav')\n",
    "\n",
    "        # Créer un dictionnaire pour stocker les métadonnées\n",
    "        metadata_dict = {}\n",
    "        for _, row in df_originall.iterrows():\n",
    "            question_id = row['question_id']\n",
    "            option_index = row['option_index']\n",
    "            response_text = row.get('response_text', None)  # Supposons qu'il y a une colonne 'response_text'\n",
    "            answer = row.get('answer', None)  # Supposons qu'il y a une colonne 'answer'\n",
    "\n",
    "            # Si 'question_id' n'est pas déjà dans le dictionnaire, l'ajouter\n",
    "            if question_id not in metadata_dict:\n",
    "                metadata_dict[question_id] = {\n",
    "                    'option_indexs': [],  # Liste pour stocker les index d'option\n",
    "                    'response_texts': [],  # Liste pour stocker les textes de réponse\n",
    "                    'answers': []  # Liste pour stocker les réponses\n",
    "                }\n",
    "            \n",
    "            # Ajouter les données associées à l'option (si elles existent)\n",
    "            if not pd.isna(option_index):\n",
    "                metadata_dict[question_id]['option_indexs'].append(option_index)\n",
    "            \n",
    "            # Ajouter le texte de réponse et la réponse si disponibles\n",
    "            metadata_dict[question_id]['response_texts'].append(response_text)\n",
    "            metadata_dict[question_id]['answers'].append(answer)\n",
    "\n",
    "        # Créer un dictionnaire pour stocker les textes des questions\n",
    "        question_text_dict = pd.Series(df_originall['question_text'].values, index=df_originall['question_id']).to_dict()\n",
    "\n",
    "        # Exclure la colonne 'question_text' pour les transformations\n",
    "        df_original = df_originall.drop(columns=['question_text'])\n",
    "\n",
    "        # Séparer la colonne 'date' avant de pivoter\n",
    "        date_column = df_original[['session_id', 'date', 'comment', 'longitude']].drop_duplicates()  # Une seule ligne par session\n",
    "\n",
    "        # Ajouter un suffixe aux colonnes 'option_index' et 'response_text'\n",
    "        df_original['variable'] = df_original.groupby(['session_id', 'question_id']).cumcount().astype(str)\n",
    "\n",
    "        # Pivoter les données en excluant la colonne 'date'\n",
    "        df_transformed = df_original.pivot(index='session_id', columns=['question_id', 'variable'], values=['option_index', 'response_text', 'answer'])\n",
    "\n",
    "        # Aplatir les niveaux de colonnes\n",
    "        df_transformed.columns = [f'{col[1]}_{col[0]}' for col in df_transformed.columns]\n",
    "\n",
    "        # Réinitialiser l'index\n",
    "        df_transformed = df_transformed.reset_index()\n",
    "\n",
    "        # Réassocier la colonne 'date' à la bonne session après le pivot\n",
    "        df_transformed = pd.merge(df_transformed, date_column, on='session_id', how='left')\n",
    "\n",
    "        # Renommer les colonnes selon le format final en utilisant un dictionnaire\n",
    "        column_rename_dict = {}\n",
    "        for col in df_transformed.columns:\n",
    "            if len(col) == 2:  # S'assurer que la colonne a deux parties\n",
    "                question_id = col[0].split('_')[0]\n",
    "                column_type = col[0].split('_')[1] if '_' in col[0] else ''  # soit 'option_index' ou 'response_text'\n",
    "                new_column_name = f'{question_id}_{col[1]}_{column_type}'\n",
    "                column_rename_dict[col] = new_column_name\n",
    "\n",
    "        # Renommer les colonnes selon le dictionnaire créé\n",
    "        df_transformed = df_transformed.rename(columns=column_rename_dict)\n",
    "\n",
    "        # Enregistrer le DataFrame transformé en CSV\n",
    "        df_transformed.to_csv(path, index=False, encoding='utf-8')\n",
    "\n",
    "        #=============================================== STEP 2 : transformé les titres avec Q pour le sav\n",
    "\n",
    "\n",
    "        # Détecter l'encodage du fichier CSV\n",
    "        with open(path, 'rb') as f:\n",
    "            result = chardet.detect(f.read())\n",
    "\n",
    "        # Utiliser l'encodage détecté pour lire le fichier CSV\n",
    "        df_original = pd.read_csv(path, encoding=result['encoding'])\n",
    "\n",
    "        # Créer des dictionnaires pour stocker les correspondances entre les indices et les lettres\n",
    "        option_index_dict = {}\n",
    "        response_text_dict = {}\n",
    "        answer_dict = {}\n",
    "\n",
    "        # Liste pour stocker les questions à multiple options\n",
    "        multiple_option_questions = {}\n",
    "\n",
    "        # Renommer les colonnes selon le format final en utilisant un dictionnaire\n",
    "        column_rename_dict = {}\n",
    "        for col in df_original.columns:\n",
    "            if 'option_index' in col:\n",
    "                question_id, index = col.split('_')[0], df_original[col].iloc[0]\n",
    "                new_col = f'Q_{question_id}_O_{index}'\n",
    "                option_index_dict[col] = new_col  # Stocker l'ancienne et la nouvelle colonne dans le dictionnaire\n",
    "                \n",
    "                # Ajouter la question à multiple_option_questions s'il y a plusieurs \"O\" pour un même question_id\n",
    "                if question_id not in multiple_option_questions:\n",
    "                    multiple_option_questions[question_id] = set()  # Utiliser un set pour éviter les doublons\n",
    "                multiple_option_questions[question_id].add(new_col)  # Ajouter les options pour cette question\n",
    "\n",
    "            elif 'response_text' in col:\n",
    "                question_id, index = col.split('_')[0], df_original[col.replace('response_text', 'option_index')].iloc[0]\n",
    "                new_col = f'Q_{question_id}_R_{index}'\n",
    "                response_text_dict[col] = new_col  # Stocker l'ancienne et la nouvelle colonne dans le dictionnaire\n",
    "            elif 'answer' in col:  # Ajouter la logique pour renommer les colonnes \"answer\"\n",
    "                question_id, index = col.split('_')[0], df_original[col.replace('answer', 'option_index')].iloc[0]\n",
    "                new_col = f'Q_{question_id}_A_{index}'\n",
    "                answer_dict[col] = new_col  # Stocker l'ancienne et la nouvelle colonne dans le dictionnaire\n",
    "            else:\n",
    "                new_col = col  # Si la colonne ne correspond pas à l'un des types ci-dessus, on ne change pas le nom\n",
    "\n",
    "            column_rename_dict[col] = new_col\n",
    "\n",
    "        # Filtrer les questions qui ont plusieurs options (plus d'une colonne O associée)\n",
    "        multiple_option_questions = {q_id: options for q_id, options in multiple_option_questions.items() if len(options) > 1}\n",
    "\n",
    "        # Utiliser les dictionnaires pour renommer les colonnes \"option_index\", \"response_text\" et \"answer\"\n",
    "        df_original = df_original.rename(columns={**option_index_dict, **response_text_dict, **answer_dict})\n",
    "\n",
    "        # Utiliser le dictionnaire pour renommer toutes les colonnes selon le format final\n",
    "        df_original = df_original.rename(columns=column_rename_dict)\n",
    "\n",
    "        # Enregistrer le DataFrame transformé en CSV\n",
    "        df_original.to_csv(path, index=False, encoding='utf-8')\n",
    "\n",
    "        #============================================== STEP 3 : Organier les colonnes question avec son option et réponse\n",
    "\n",
    "        # Charger le fichier CSV transformé\n",
    "        df = pd.read_csv(path)\n",
    "\n",
    "        # Extraire les noms de colonnes liés aux option_indexs (O) et aux réponses (R) et answer (A)\n",
    "        option_columns = [col for col in df.columns if 'O_' in col]\n",
    "        #response_columns = [col for col in df.columns if 'R_' in col]\n",
    "        #answer_columns = [col for col in df.columns if 'A_' in col]\n",
    "\n",
    "        # Organiser les colonnes de O suivies de leurs colonnes de R pour chaque question\n",
    "        new_columns_order = []\n",
    "        for option_col in option_columns:\n",
    "            question_id = option_col.split('_')[1]\n",
    "            response_col = option_col.replace('O_', 'R_')\n",
    "            answer_col = option_col.replace('O_', 'A_')\n",
    "            \n",
    "            # Ajouter les colonnes O, R, et A pour chaque question dans le bon ordre\n",
    "            new_columns_order.extend([option_col, response_col, answer_col])\n",
    "\n",
    "        # Créer un nouveau DataFrame réorganisé\n",
    "        df_reorganized = df[['session_id'] + ['date'] + ['comment'] + ['longitude']+new_columns_order]\n",
    "\n",
    "        # Enregistrer le DataFrame réorganisé en CSV\n",
    "        df_reorganized.to_csv(path, index=False, encoding='utf-8')\n",
    "\n",
    "        #============================================== STEP 4 : distinguer les questions à champ libre et faire en sorte a avoir des float sur les titres\n",
    "\n",
    "      \n",
    "        \n",
    "\n",
    "        # Charger le fichier CSV réorganisé\n",
    "        df_reorganized = pd.read_csv(path, encoding='utf-8')\n",
    "\n",
    "        # Convertir la colonne date en type datetime\n",
    "        df_reorganized['date'] = pd.to_datetime(df_reorganized['date'])\n",
    "\n",
    "        # Ouvrir le fichier CSV en mode binaire pour détecter l'encodage\n",
    "        with open(path, 'rb') as f:\n",
    "            result = chardet.detect(f.read())\n",
    "\n",
    "        # Charger le fichier CSV avec l'encodage détecté\n",
    "        #df_csv = pd.read_csv(path, encoding=result['encoding'])\n",
    "\n",
    "        # Convertir option_index en entier si possible\n",
    "        #df_csv['option_index'] = pd.to_numeric(df_csv['option_index'], errors='coerce').dropna().astype('Int64')\n",
    "\n",
    "        # 1. Lister les questions à champ libre (où l'option_index est NaN)\n",
    "        questions_reponse_libre = [q_id for q_id, data in metadata_dict.items() if not data['option_indexs']]\n",
    "\n",
    "        # 2. Parcourir chaque question à réponse libre et effectuer les modifications nécessaires\n",
    "        for question_id in questions_reponse_libre:\n",
    "            # 2.1. Renommer la colonne de la question libre en supprimant 'O_' et tout ce qui suit\n",
    "            old_column_name_prefix = f\"Q_{question_id}_O_\"\n",
    "            \n",
    "            # Rechercher les colonnes qui correspondent à ce modèle\n",
    "            matching_columns = [col for col in df_reorganized.columns if col.startswith(old_column_name_prefix)]\n",
    "            \n",
    "            for col in matching_columns:\n",
    "                # 2.2. Remplacer le titre en supprimant 'O_' et tout ce qui suit\n",
    "                new_column_name = col.split('_O_')[0]  # Conserver uniquement la partie avant '_O_'\n",
    "                df_reorganized.rename(columns={col: new_column_name}, inplace=True)\n",
    "                \n",
    "                # 3. Remplir la colonne renommée avec les données de la colonne correspondante 'R_'\n",
    "                r_column = col.replace('O_', 'R_')\n",
    "                if r_column in df_reorganized.columns:\n",
    "                    df_reorganized[new_column_name] = df_reorganized[r_column]\n",
    "                \n",
    "                # 4. Supprimer la colonne 'R_' et 'A_' correspondantes\n",
    "                a_column = col.replace('O_', 'A_')\n",
    "                if r_column in df_reorganized.columns:\n",
    "                    df_reorganized.drop(columns=[r_column], inplace=True)\n",
    "                if a_column in df_reorganized.columns:\n",
    "                    df_reorganized.drop(columns=[a_column], inplace=True)\n",
    "\n",
    "        # Assurer que les noms de colonnes avec 'O_' aient des entiers dans leur nom, et non des floats\n",
    "        # Liste des suffixes à traiter\n",
    "        suffixes = ['O', 'A', 'R']\n",
    "\n",
    "        for suffix in suffixes:\n",
    "            for col in df_reorganized.columns:\n",
    "                if f'_{suffix}_' in col:\n",
    "                    parts = col.split(f'_{suffix}_')\n",
    "                    if len(parts) > 1:\n",
    "                        try:\n",
    "                            # Convertir l'option_index en entier\n",
    "                            option_index = int(float(parts[1]))\n",
    "                            new_col_name = f\"{parts[0]}_{suffix}_{option_index}\"\n",
    "                            df_reorganized.rename(columns={col: new_col_name}, inplace=True)\n",
    "                        except ValueError:\n",
    "                            pass  # Si l'option_index n'est pas un nombre valide, on l'ignore\n",
    "\n",
    "        # Écrire le fichier SAV après les modifications\n",
    "        pyreadstat.write_sav(df_reorganized, sav_path)\n",
    "\n",
    "        #============================================== STEP 5 : création des values labels en supprimant les colonnes Response et Answer\n",
    "\n",
    "        # Charger le fichier SAV et ses métadonnées\n",
    "        df_sav, meta = pyreadstat.read_sav(sav_path)\n",
    "\n",
    "        # Transformer la colonne 'date' au format datetime si nécessaire\n",
    "        df_sav['date'] = pd.to_datetime(df_sav['date'])\n",
    "\n",
    "        # Créer un dictionnaire pour stocker les value labels\n",
    "        value_labels_dict = {}\n",
    "\n",
    "        # Ouvrir le fichier CSV en mode binaire pour détecter l'encodage\n",
    "        with open(path, 'rb') as f:\n",
    "            result = chardet.detect(f.read())\n",
    "\n",
    "        # Charger le fichier CSV avec l'encodage détecté\n",
    "        #df_csv = pd.read_csv(path, encoding=result['encoding'])\n",
    "\n",
    "        #----\n",
    "        # Itérer sur chaque question dans le dictionnaire metadata_dict\n",
    "        for question_id, data in metadata_dict.items():\n",
    "            option_indexs = data['option_indexs']  # Liste des option_indexs\n",
    "            response_texts = data['response_texts']  # Liste des response_texts associés\n",
    "\n",
    "            # Assurez-vous qu'il n'y a pas de doublons dans 'option_index' et 'response_texts'\n",
    "            unique_option_indexs = list(dict.fromkeys(option_indexs))\n",
    "            unique_response_texts = list(dict.fromkeys(response_texts))\n",
    "\n",
    "            # Créer le dictionnaire des value labels en associant option_index à response_text\n",
    "            value_labels_dict[question_id] = dict(zip(unique_option_indexs, unique_response_texts))\n",
    "        #----\n",
    "\n",
    "        # S'assurer que les variable_value_labels existent dans les métadonnées\n",
    "        if meta.variable_value_labels is None:\n",
    "            meta.variable_value_labels = {}\n",
    "\n",
    "        # Ajouter les value labels aux métadonnées\n",
    "        for question_id, value_dict in value_labels_dict.items():\n",
    "            for option_index, response_text in value_dict.items():\n",
    "                # Convertir option_index en entier\n",
    "                option_index_int = int(float(option_index))  # Gérer le cas où option_index est un flottant\n",
    "                var_name = f\"Q_{question_id}_O_{option_index_int}\"\n",
    "\n",
    "                # Vérifier si la question est à choix unique ou multiple\n",
    "                if f\"Q_{question_id}_O_\" in var_name and not var_name.endswith('.0.1'):  # Choix unique : Une seule colonne 'O'\n",
    "                    \n",
    "                    # S'assurer que la colonne est bien présente dans les métadonnées\n",
    "                    if var_name not in meta.variable_value_labels:\n",
    "                        meta.variable_value_labels[var_name] = {}\n",
    "                    \n",
    "                    # Remplacer O par NaN si A contient NaN\n",
    "                \n",
    "                    if f\"Q_{question_id}_A_{option_index_int}\" in df_sav.columns :\n",
    "                        df_sav.loc[pd.isna(df_sav[f\"Q_{question_id}_A_{option_index_int}\"]), var_name] = pd.NA\n",
    "\n",
    "                    # Ajouter le label pour l'option choisie\n",
    "                    meta.variable_value_labels[var_name][option_index_int] = response_text\n",
    "                    \n",
    "                \n",
    "                # Ajouter le value label pour chaque option_index qui existe \n",
    "                for option_index_int, response_text in value_dict.items():\n",
    "                    if pd.notna(option_index_int):\n",
    "                        meta.variable_value_labels[var_name][option_index_int] = response_text\n",
    "\n",
    "        #-----\n",
    "        # Vérifiez que vous parcourez les bonnes clés\n",
    "        for question_id, data in metadata_dict.items():\n",
    "            # Imprimer le type de question_id pour déboguer\n",
    "            question_id_str = str(question_id)\n",
    "            \n",
    "            # Vérifier si question_id est une chaîne de caractères\n",
    "            if question_id_str in multiple_option_questions:\n",
    "                # Identifier la dernière option index de la question\n",
    "                dernier_option_index = max(data['option_indexs']) # Prendre le dernier option_index\n",
    "                \n",
    "                # Construire la variable correspondant à cette dernière option\n",
    "                dernier_option_var = f\"Q_{question_id}_O_{dernier_option_index}.1\"\n",
    "\n",
    "                # Vérifier si cette colonne existe dans le DataFrame\n",
    "                if dernier_option_var in df_sav.columns:\n",
    "                    # Renommer la colonne en fonction du format S_Q_{question_id}_{dernier_option_index}\n",
    "                    dernier_option_index_int = int(float(dernier_option_index))\n",
    "                    new_column_name = f\"S_Q_{question_id}_{dernier_option_index_int}\"\n",
    "                    df_sav.rename(columns={dernier_option_var: new_column_name}, inplace=True)\n",
    "\n",
    "                    # Remplacer le contenu de la nouvelle colonne avec celui de la colonne 'R_' correspondante\n",
    "                    r_column = f\"Q_{question_id}_R_{dernier_option_index}.1\"\n",
    "                    if r_column in df_sav.columns:\n",
    "                        df_sav[new_column_name] = df_sav[r_column]\n",
    "\n",
    "        #-----\n",
    "        # Supprimer les colonnes A et R\n",
    "        columns_to_drop = [col for col in df_sav.columns if '_A_' in col or '_R_' in col]\n",
    "        df_sav = df_sav.drop(columns=columns_to_drop)\n",
    "\n",
    "        #-----\n",
    "        # Vérifier si meta.column_labels est une liste\n",
    "        if isinstance(meta.column_labels, list):\n",
    "            # Créer un dictionnaire en associant chaque colonne à son libellé ou une chaîne vide si pas de libellé\n",
    "            meta.column_labels = {col: \"\" for col in df_sav.columns}\n",
    "\n",
    "        # Mettre à jour les labels des colonnes\n",
    "        meta.column_labels = {col: label for col, label in meta.column_labels.items() if col in df_sav.columns}\n",
    "\n",
    "        # Réécrire le fichier SAV avec les value labels mis à jour\n",
    "        pyreadstat.write_sav(df_sav, \n",
    "                            sav_path, \n",
    "                            file_label=\"Updated SAV with Corrected Value Labels\",\n",
    "                            variable_value_labels=meta.variable_value_labels,\n",
    "                            column_labels=meta.column_labels)\n",
    "\n",
    "        #============================================== STEP 6 : modifier les titres en Q_idquestion pour les questions à choix unique\n",
    "\n",
    "        # Charger le fichier SAV avec les value labels\n",
    "        df_sav, meta = pyreadstat.read_sav(sav_path)\n",
    "\n",
    "        # Identifier les colonnes à renommer\n",
    "        column_mapping = {}\n",
    "\n",
    "        for col in df_sav.columns:\n",
    "            if col.startswith('Q_') and '_O_' in col:\n",
    "                question_id = col.split('_')[1]  # Extraire l'ID de la question\n",
    "                if question_id not in column_mapping:\n",
    "                    column_mapping[question_id] = []\n",
    "                column_mapping[question_id].append(col)\n",
    "\n",
    "        # Créer un dictionnaire de renommage pour les colonnes à choix unique\n",
    "        rename_dict = {}\n",
    "        for question_id, columns in column_mapping.items():\n",
    "            if len(columns) == 1:  # S'il n'y a qu'une seule colonne pour cette question\n",
    "                original_column = columns[0]\n",
    "                new_column_name = f'Q_{question_id}'  # Renommer vers Q_1, Q_2, etc.\n",
    "                rename_dict[original_column] = new_column_name\n",
    "\n",
    "        # Conserver les value labels avant de renommer\n",
    "        value_labels_backup = {col: meta.variable_value_labels.get(col, {}) for col in rename_dict.keys()}\n",
    "\n",
    "        # Renommer les colonnes dans le DataFrame\n",
    "        df_sav.rename(columns=rename_dict, inplace=True)\n",
    "\n",
    "        # Réappliquer les value labels aux nouvelles colonnes renommées\n",
    "        for original_col, new_col in rename_dict.items():\n",
    "            if new_col not in meta.variable_value_labels:\n",
    "                meta.variable_value_labels[new_col] = value_labels_backup[original_col]\n",
    "\n",
    "        # Réécrire le fichier SAV avec les colonnes renommées et les value labels\n",
    "        pyreadstat.write_sav(df_sav, \n",
    "                            sav_path, \n",
    "                            file_label=\"Updated SAV with Unique Column Titles\",\n",
    "                            variable_value_labels=meta.variable_value_labels,\n",
    "                            column_labels=meta.column_labels)  # Conserver les labels des colonnes\n",
    "\n",
    "        #print(\"Les colonnes ont été renommées tout en préservant les value labels.\")\n",
    "        #============================================== STEP 7 : création des libellés en gardant les value labels\n",
    "\n",
    "        # Charger le fichier SAV avec les value labels déjà présents\n",
    "        df_sav, meta = pyreadstat.read_sav(sav_path)\n",
    "\n",
    "        # Déterminer le maximum d'index d'options à partir des noms de colonnes\n",
    "        max_option_index = 0\n",
    "        for col in df_sav.columns:\n",
    "            if col.startswith(\"Q_\"):  # S'assurer qu'il s'agit d'une colonne de question\n",
    "                # Extraire l'index d'option de la colonne, par exemple Q_1_O_3.1\n",
    "                parts = col.split(\"_\")\n",
    "                if len(parts) > 3 and parts[2] == \"O\":\n",
    "                    option_index = int(parts[3])  # Convertir l'index d'option en entier\n",
    "                    max_option_index = max(max_option_index, option_index)\n",
    "\n",
    "        # Si metadata.column_labels est une liste, la convertir en dictionnaire\n",
    "        if isinstance(meta.column_labels, list):\n",
    "            meta.column_labels = {col: \"\" for col in df_sav.columns}\n",
    "\n",
    "        # Créer un dictionnaire pour les libellés de colonnes\n",
    "        column_labels = {}\n",
    "\n",
    "        # Ajouter les libellés pour les colonnes de questions à choix unique\n",
    "        for question_id in question_text_dict:\n",
    "            # Libellé pour la colonne Q_idquestion\n",
    "            q_col_name = f\"Q_{question_id}\"\n",
    "            if q_col_name in df_sav.columns:\n",
    "                column_labels[q_col_name] = question_text_dict[question_id]  # Utiliser le texte de la question\n",
    "\n",
    "        # Ajouter les libellés pour les colonnes de questions à options multiples\n",
    "        for question_id in question_text_dict:\n",
    "            for option_index in range(1, max_option_index + 1):  # Utiliser le max_option_index trouvé\n",
    "                # Libellé pour les colonnes Q_idquestion_O_optionindex\n",
    "                q_col_name = f\"Q_{question_id}_O_{option_index}\"\n",
    "                if q_col_name in df_sav.columns:\n",
    "                    column_labels[q_col_name] = question_text_dict[question_id]  # Utiliser le texte de la question\n",
    "\n",
    "                # Libellé pour les colonnes S_Q_idquestion_optionindex\n",
    "                s_col_name = f\"S_Q_{question_id}_{option_index}\"\n",
    "                if s_col_name in df_sav.columns:\n",
    "                    column_labels[s_col_name] = f\"{question_text_dict[question_id]} Autres\"  # Texte de la question + 'Autres'\n",
    "\n",
    "        # Ajouter les libellés pour les autres colonnes (nom de colonne)\n",
    "        for col in df_sav.columns:\n",
    "            if col not in column_labels:\n",
    "                column_labels[col] = col  # Utiliser le nom de la colonne comme libellé\n",
    "\n",
    "        # Mettre à jour les column_labels\n",
    "        meta.column_labels.update(column_labels)\n",
    "\n",
    "        # Réécrire le fichier SAV avec les column labels mis à jour\n",
    "        pyreadstat.write_sav(df_sav, sav_path, \n",
    "                            column_labels=meta.column_labels, \n",
    "                            variable_value_labels=meta.variable_value_labels)\n",
    "        #============================================== STEP 8 : trouver les measures\n",
    "\n",
    "        \n",
    "\n",
    "        # Charger le fichier SAV avec ses métadonnées\n",
    "        df, meta = pyreadstat.read_sav(sav_path)\n",
    "\n",
    "        # Fonction pour déterminer le type de measure\n",
    "        def set_measure(df, meta):\n",
    "            # On récupère les informations actuelles\n",
    "            variable_measure = meta.variable_measure.copy()  # Copier pour éviter de modifier directement l'original\n",
    "            variable_value_labels = meta.variable_value_labels  # Pour vérifier si une colonne a des value labels\n",
    "            \n",
    "            for col in df.columns:\n",
    "                # 1. Ordinal: Si la colonne a des value labels (multiple choix ou unique avec options) ou de type date\n",
    "                if col in variable_value_labels or df[col].dtype == 'datetime64[ns]':\n",
    "                    variable_measure[col] = \"ordinal\"\n",
    "                \n",
    "                # 2. Échelle (Scale): Si c'est un champ libre avec réponse numérique sans value labels\n",
    "                elif df[col].dtype == 'float64' or df[col].dtype == 'int64':\n",
    "                    variable_measure[col] = \"scale\"\n",
    "                \n",
    "                # 3. Nominal: Si c'est un champ libre texte sans value labels\n",
    "                elif df[col].dtype == 'object':\n",
    "                    variable_measure[col] = \"nominal\"\n",
    "\n",
    "            return variable_measure\n",
    "\n",
    "        # Mettre à jour les measures\n",
    "        updated_variable_measure = set_measure(df, meta)\n",
    "\n",
    "        # Sauvegarder le fichier avec les mesures mises à jour tout en gardant les anciennes métadonnées\n",
    "        pyreadstat.write_sav(\n",
    "            df,\n",
    "            sav_path,\n",
    "            variable_value_labels=meta.variable_value_labels,\n",
    "            column_labels=meta.column_labels,\n",
    "            variable_measure=updated_variable_measure\n",
    "        )\n",
    "\n",
    "        #============================================== STEP 9 : création des -1 pour NaN et l'ajouter dans manquants des vues des variables\n",
    "        \n",
    "        # Charger le fichier SAV avec les value labels déjà présents\n",
    "        df_sav, meta = pyreadstat.read_sav(sav_path)\n",
    "\n",
    "        # Créer un dictionnaire pour stocker les plages de valeurs manquantes (missing_ranges)\n",
    "        missing_ranges = {}\n",
    "\n",
    "        # Itérer sur les colonnes pour remplir les valeurs manquantes dans la vue des variables\n",
    "        for col in df_sav.columns:\n",
    "            # Vérifier si la colonne correspond à une question Q et si elle est numérique\n",
    "            if col.startswith('Q') and pd.api.types.is_numeric_dtype(df_sav[col]):\n",
    "                \n",
    "                # Remplir avec -1 si la valeur est NaN dans la vue des données\n",
    "                df_sav[col] = df_sav[col].fillna(-1)\n",
    "\n",
    "                # Convertir en entier\n",
    "                df_sav[col] = df_sav[col].astype(int)\n",
    "                \n",
    "                # Définir -1 comme valeur manquante dans la vue des variables pour cette colonne\n",
    "                missing_ranges[col] = [-1]  # Plage de valeurs manquantes fixée à -1\n",
    "\n",
    "        # Vérifier et corriger les value labels pour s'assurer qu'ils sont tous des entiers\n",
    "        for col in meta.variable_value_labels.keys():\n",
    "            if col in df_sav.columns:\n",
    "                \n",
    "                # Assurez-vous que les labels de valeur soient des entiers\n",
    "                meta.variable_value_labels[col] = {int(k): v for k, v in meta.variable_value_labels[col].items()}\n",
    "\n",
    "                \n",
    "        # Enregistrer le DataFrame mis à jour dans un nouveau fichier SAV avec les valeurs manquantes dans la vue des variables\n",
    "        pyreadstat.write_sav(df_sav, sav_path, \n",
    "                            variable_value_labels=meta.variable_value_labels,\n",
    "                            column_labels=meta.column_labels,\n",
    "                            variable_measure=meta.variable_measure,\n",
    "                            missing_ranges=missing_ranges)  # Ajouter les valeurs manquantes dans la vue des variables\n",
    "        #supprimer le csv\n",
    "        os.remove(path)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Une erreur s'est produite : {e}\")\n",
    "\n",
    "# Exécution de la fonction avec le chemin passé en argument\n",
    "if __name__ == \"__main__\":\n",
    "    if len(sys.argv) > 1:\n",
    "        export_csv_to_sav(sys.argv[1])\n",
    "    else:\n",
    "        print(\"Veuillez fournir un chemin vers le fichier CSV.\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_csv_to_sav('/Users/Lisa/Desktop/response.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}